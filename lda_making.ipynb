{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news20 = fetch_20newsgroups()\n",
    "news = news20.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n                          evaluate_every=-1, learning_decay=0.7,\n                          learning_method='online', learning_offset=10.0,\n                          max_doc_update_iter=100, max_iter=10,\n                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n                          perp_tol=0.1, random_state=None,\n                          topic_word_prior=None, total_samples=1000000.0,\n                          verbose=0)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 単語の出現頻度データを作成\n",
    "cv = CV(max_df=0.9, min_df=5, stop_words='english')#ここもわけわからん。max_difとmin_dif\n",
    "cved = cv.fit_transform(news)\n",
    "len(cv.get_feature_names())\n",
    "\n",
    "# LDAのモデル作成と学習\n",
    "lda = LDA(learning_method = 'online')\n",
    "lda.fit(cved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "topic #0\nax, max, g9v, b8f, a86, 145, 0d, pl, 1d9, 34u, 0t, 3t, 75u, 1t, 2di, cx, bhj, _o, giz \n\ntopic #1\npeople, government, israel, said, turkish, israeli, war, rights, state, jews, armenian, states, armenians, right, world, american, did, today, 000 \n\ntopic #2\ncom, key, gov, nasa, use, encryption, chip, public, clipper, access, writes, posting, article, keys, government, distribution, ___, data, security \n\ntopic #3\nedu, com, writes, article, gun, posting, host, nntp, university, like, colorado, bike, netcom, just, au, dod, don, guns, cs \n\ntopic #4\nedu, article, writes, university, com, cs, uiuc, year, good, pitt, don, health, just, like, cso, new, know, news, time \n\ntopic #5\ngod, people, edu, think, don, say, does, believe, just, know, jesus, writes, com, like, way, christian, article, time, life \n\ntopic #6\nspace, 00, 10, 25, 15, 11, 20, 16, 12, 14, 17, 30, 13, 18, db, 24, 19, 23, 22 \n\ntopic #7\nedu, com, posting, nntp, host, article, writes, university, drive, just, like, car, don, know, new, scsi, ca, distribution, does \n\ntopic #8\nedu, file, use, windows, com, program, mail, available, using, information, software, window, version, files, thanks, help, graphics, email, does \n\ntopic #9\ndon, think, ca, team, just, writes, year, time, game, like, going, good, article, know, ll, did, mr, make, years \n\n"
    }
   ],
   "source": [
    "features = cv.get_feature_names()\n",
    "\n",
    "\n",
    "#↓ここに書いてることよくわからんチン\n",
    "for tn in range(10):\n",
    "    print(\"topic #\"+str(tn))#というかここから下がどうなってるかわからん\n",
    "    row = lda.components_[tn]\n",
    "    words = ', '.join([features[i] for i in row.argsort()[:-20:-1]])\n",
    "    print(words, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}